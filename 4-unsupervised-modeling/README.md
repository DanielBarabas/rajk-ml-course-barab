# DBSCAN

## Checkout clustering possibilities

Checkout sklearn algorithms:<br>
https://scikit-learn.org/stable/modules/clustering.html<br>
Whats good in using sklearn models in whatever you can?<br>

## Explain the DBSCAN algorithm

eps, min_samples and metric<br>
core, border points and outliers<br>

# UMAP and T-SNE

## UMAP explained visually
https://pair-code.github.io/understanding-umap/<br>

## UMAP Notebook

## Resources for eager beavers:
### Explanations
explanation: https://umap-learn.readthedocs.io/en/latest/how_umap_works.html<br>
mathy: https://pair-code.github.io/understanding-umap/supplement.html<br>
### Usecases:
UMAP for feature extraction: https://umap-learn.readthedocs.io/en/latest/auto_examples/plot_feature_extraction_classification.html#sphx-glr-auto-examples-plot-feature-extraction-classification-py<br>
Algorithm comparison: https://umap-learn.readthedocs.io/en/latest/auto_examples/plot_algorithm_comparison.html#sphx-glr-auto-examples-plot-algorithm-comparison-py<br>


# Feature engineering

Bias-variance tradeoff --> model complexity is bounded --> engineer information to be picked up easily.<br>
Model complexity is the cost of incorporating information, which can be lowered using feature engineering. <br>

# Decision tree

Explain the model<br>
https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html
parameters<br>

# Feature engineering notebook

if we have time:
# Lapker data

